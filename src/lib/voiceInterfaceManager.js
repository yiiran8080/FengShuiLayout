// ğŸ¤ Voice Interface Integration System
// Immediate Improvement: Speech recognition and text-to-speech capabilities

class VoiceInterfaceManager {
	constructor() {
		this.isSupported = this.checkBrowserSupport();
		this.isListening = false;
		this.isSpeaking = false;

		// Speech recognition setup
		this.recognition = null;
		this.synthesis = window.speechSynthesis;

		// Voice configuration
		this.voiceConfig = {
			language: "zh-TW",
			rate: 0.9,
			pitch: 1.0,
			volume: 0.8,
			voice: null,
		};

		// Recognition configuration
		this.recognitionConfig = {
			continuous: false,
			interimResults: true,
			maxAlternatives: 3,
			language: "zh-TW",
		};

		// Command patterns for voice control
		this.voiceCommands = {
			start: ["é–‹å§‹", "ä½ å¥½", "å—¨", "hello", "hi"],
			stop: ["åœæ­¢", "çµæŸ", "stop", "æš«åœ"],
			repeat: ["é‡è¤‡", "å†èªªä¸€é", "repeat", "é‡èªª"],
			louder: ["å¤§è²ä¸€é»", "éŸ³é‡å¤§", "louder", "å¤§è²"],
			quieter: ["å°è²ä¸€é»", "éŸ³é‡å°", "quieter", "å°è²"],
			faster: ["å¿«ä¸€é»", "å¿«é€Ÿ", "faster", "åŠ é€Ÿ"],
			slower: ["æ…¢ä¸€é»", "æ…¢é€Ÿ", "slower", "æ¸›é€Ÿ"],
			clear: ["æ¸…é™¤", "é‡æ–°é–‹å§‹", "clear", "æ¸…ç©º"],
		};

		// Initialize system
		this.initialize();
	}

	// Check browser support for speech APIs
	checkBrowserSupport() {
		const hasRecognition =
			"webkitSpeechRecognition" in window ||
			"SpeechRecognition" in window;
		const hasSynthesis = "speechSynthesis" in window;

		console.log(
			`ğŸ¤ èªéŸ³æ”¯æ´ç‹€æ…‹: èªéŸ³è­˜åˆ¥=${hasRecognition}, èªéŸ³åˆæˆ=${hasSynthesis}`
		);

		return {
			recognition: hasRecognition,
			synthesis: hasSynthesis,
			full: hasRecognition && hasSynthesis,
		};
	}

	// Initialize voice interface
	async initialize() {
		if (!this.isSupported.full) {
			console.warn("âš ï¸ ç€è¦½å™¨ä¸å®Œå…¨æ”¯æ´èªéŸ³åŠŸèƒ½");
			return false;
		}

		try {
			// Initialize speech recognition
			this.setupSpeechRecognition();

			// Initialize speech synthesis
			await this.setupSpeechSynthesis();

			// Setup voice commands
			this.setupVoiceCommands();

			console.log("âœ… èªéŸ³ä»‹é¢åˆå§‹åŒ–å®Œæˆ");
			return true;
		} catch (error) {
			console.error("ğŸš¨ èªéŸ³ä»‹é¢åˆå§‹åŒ–éŒ¯èª¤:", error);
			return false;
		}
	}

	// Setup speech recognition
	setupSpeechRecognition() {
		const SpeechRecognition =
			window.SpeechRecognition || window.webkitSpeechRecognition;

		if (!SpeechRecognition) {
			throw new Error("Speech Recognition not supported");
		}

		this.recognition = new SpeechRecognition();

		// Configure recognition
		Object.assign(this.recognition, this.recognitionConfig);

		// Setup event handlers
		this.recognition.onstart = () => {
			this.isListening = true;
			this.onListeningStart();
		};

		this.recognition.onresult = (event) => {
			this.handleSpeechResult(event);
		};

		this.recognition.onend = () => {
			this.isListening = false;
			this.onListeningEnd();
		};

		this.recognition.onerror = (event) => {
			console.error("ğŸš¨ èªéŸ³è­˜åˆ¥éŒ¯èª¤:", event.error);
			this.onRecognitionError(event);
		};

		this.recognition.onnomatch = () => {
			console.warn("âš ï¸ ç„¡æ³•è­˜åˆ¥èªéŸ³");
			this.onNoMatch();
		};
	}

	// Setup speech synthesis
	async setupSpeechSynthesis() {
		if (!this.synthesis) {
			throw new Error("Speech Synthesis not supported");
		}

		// Wait for voices to load
		await this.waitForVoices();

		// Find best Chinese voice
		this.voiceConfig.voice = this.findBestChineseVoice();

		if (!this.voiceConfig.voice) {
			console.warn("âš ï¸ æ‰¾ä¸åˆ°ä¸­æ–‡èªéŸ³ï¼Œä½¿ç”¨é è¨­èªéŸ³");
		}
	}

	// Wait for voices to be available
	waitForVoices() {
		return new Promise((resolve) => {
			const voices = this.synthesis.getVoices();
			if (voices.length > 0) {
				resolve(voices);
			} else {
				this.synthesis.onvoiceschanged = () => {
					resolve(this.synthesis.getVoices());
				};
			}
		});
	}

	// Find the best Chinese voice
	findBestChineseVoice() {
		const voices = this.synthesis.getVoices();

		// Preferred voice order
		const preferredVoices = ["zh-TW", "zh-CN", "zh-HK", "zh", "Chinese"];

		for (const preferred of preferredVoices) {
			const voice = voices.find(
				(v) =>
					v.lang.includes(preferred) ||
					v.name.toLowerCase().includes("chinese") ||
					v.name.toLowerCase().includes("mandarin")
			);
			if (voice) return voice;
		}

		return voices[0]; // Fallback to first available voice
	}

	// Setup voice commands recognition
	setupVoiceCommands() {
		this.commandPatterns = new Map();

		Object.entries(this.voiceCommands).forEach(([command, patterns]) => {
			patterns.forEach((pattern) => {
				this.commandPatterns.set(pattern.toLowerCase(), command);
			});
		});
	}

	// Start listening for speech
	startListening(options = {}) {
		if (!this.isSupported.recognition || this.isListening) {
			return false;
		}

		try {
			// Apply any custom options
			if (options.continuous !== undefined) {
				this.recognition.continuous = options.continuous;
			}
			if (options.interimResults !== undefined) {
				this.recognition.interimResults = options.interimResults;
			}

			this.recognition.start();
			console.log("ğŸ¤ é–‹å§‹èªéŸ³è­˜åˆ¥...");
			return true;
		} catch (error) {
			console.error("ğŸš¨ ç„¡æ³•é–‹å§‹èªéŸ³è­˜åˆ¥:", error);
			return false;
		}
	}

	// Stop listening
	stopListening() {
		if (this.isListening && this.recognition) {
			this.recognition.stop();
			console.log("ğŸ›‘ åœæ­¢èªéŸ³è­˜åˆ¥");
		}
	}

	// Speak text using TTS
	speak(text, options = {}) {
		if (!this.isSupported.synthesis || this.isSpeaking) {
			return false;
		}

		try {
			// Stop any current speech
			this.synthesis.cancel();

			const utterance = new SpeechSynthesisUtterance(text);

			// Apply configuration
			utterance.voice = this.voiceConfig.voice;
			utterance.rate = options.rate || this.voiceConfig.rate;
			utterance.pitch = options.pitch || this.voiceConfig.pitch;
			utterance.volume = options.volume || this.voiceConfig.volume;
			utterance.lang = options.language || this.voiceConfig.language;

			// Setup event handlers
			utterance.onstart = () => {
				this.isSpeaking = true;
				this.onSpeechStart(text);
			};

			utterance.onend = () => {
				this.isSpeaking = false;
				this.onSpeechEnd();
			};

			utterance.onerror = (event) => {
				this.isSpeaking = false;
				console.error("ğŸš¨ èªéŸ³åˆæˆéŒ¯èª¤:", event.error);
				this.onSpeechError(event);
			};

			this.synthesis.speak(utterance);
			console.log("ğŸ”Š é–‹å§‹èªéŸ³æ’­æ”¾:", text.substring(0, 50) + "...");
			return true;
		} catch (error) {
			console.error("ğŸš¨ èªéŸ³æ’­æ”¾å¤±æ•—:", error);
			return false;
		}
	}

	// Stop speaking
	stopSpeaking() {
		if (this.isSpeaking) {
			this.synthesis.cancel();
			this.isSpeaking = false;
			console.log("ğŸ›‘ åœæ­¢èªéŸ³æ’­æ”¾");
		}
	}

	// Handle speech recognition results
	handleSpeechResult(event) {
		let finalTranscript = "";
		let interimTranscript = "";

		for (let i = event.resultIndex; i < event.results.length; i++) {
			const transcript = event.results[i][0].transcript;

			if (event.results[i].isFinal) {
				finalTranscript += transcript;
			} else {
				interimTranscript += transcript;
			}
		}

		// Handle interim results
		if (interimTranscript) {
			this.onInterimResult(interimTranscript);
		}

		// Handle final results
		if (finalTranscript) {
			console.log("ğŸ¤ èªéŸ³è­˜åˆ¥çµæœ:", finalTranscript);

			// Check for voice commands first
			const command = this.detectVoiceCommand(finalTranscript);
			if (command) {
				this.executeVoiceCommand(command, finalTranscript);
			} else {
				this.onFinalResult(finalTranscript);
			}
		}
	}

	// Detect voice commands in speech
	detectVoiceCommand(text) {
		const lowerText = text.toLowerCase().trim();

		for (const [pattern, command] of this.commandPatterns) {
			if (lowerText.includes(pattern)) {
				return command;
			}
		}

		return null;
	}

	// Execute voice commands
	executeVoiceCommand(command, originalText) {
		console.log(`ğŸ¯ åŸ·è¡ŒèªéŸ³æŒ‡ä»¤: ${command}`);

		switch (command) {
			case "stop":
				this.stopListening();
				this.stopSpeaking();
				break;

			case "repeat":
				this.onRepeatRequest();
				break;

			case "louder":
				this.adjustVolume(0.1);
				break;

			case "quieter":
				this.adjustVolume(-0.1);
				break;

			case "faster":
				this.adjustRate(0.1);
				break;

			case "slower":
				this.adjustRate(-0.1);
				break;

			case "clear":
				this.onClearRequest();
				break;

			default:
				// If command not handled, treat as regular input
				this.onFinalResult(originalText);
		}
	}

	// Adjust speech volume
	adjustVolume(delta) {
		this.voiceConfig.volume = Math.max(
			0,
			Math.min(1, this.voiceConfig.volume + delta)
		);
		console.log(
			`ğŸ”Š éŸ³é‡èª¿æ•´è‡³: ${Math.round(this.voiceConfig.volume * 100)}%`
		);
	}

	// Adjust speech rate
	adjustRate(delta) {
		this.voiceConfig.rate = Math.max(
			0.5,
			Math.min(2, this.voiceConfig.rate + delta)
		);
		console.log(
			`âš¡ èªé€Ÿèª¿æ•´è‡³: ${Math.round(this.voiceConfig.rate * 100)}%`
		);
	}

	// Get voice interface status
	getStatus() {
		return {
			isSupported: this.isSupported,
			isListening: this.isListening,
			isSpeaking: this.isSpeaking,
			voiceConfig: this.voiceConfig,
			availableVoices: this.synthesis
				? this.synthesis.getVoices().length
				: 0,
		};
	}

	// Event handlers (to be overridden by implementing class)
	onListeningStart() {
		// Override in implementation
		console.log("ğŸ¤ é–‹å§‹è†è½...");
	}

	onListeningEnd() {
		// Override in implementation
		console.log("ğŸ¤ åœæ­¢è†è½");
	}

	onInterimResult(transcript) {
		// Override in implementation
		console.log("ğŸ”„ è‡¨æ™‚çµæœ:", transcript);
	}

	onFinalResult(transcript) {
		// Override in implementation
		console.log("âœ… æœ€çµ‚çµæœ:", transcript);
	}

	onSpeechStart(text) {
		// Override in implementation
		console.log("ğŸ”Š é–‹å§‹æ’­æ”¾èªéŸ³");
	}

	onSpeechEnd() {
		// Override in implementation
		console.log("ğŸ”Š èªéŸ³æ’­æ”¾å®Œæˆ");
	}

	onRecognitionError(event) {
		// Override in implementation
		console.error("ğŸš¨ èªéŸ³è­˜åˆ¥éŒ¯èª¤:", event.error);
	}

	onSpeechError(event) {
		// Override in implementation
		console.error("ğŸš¨ èªéŸ³æ’­æ”¾éŒ¯èª¤:", event.error);
	}

	onNoMatch() {
		// Override in implementation
		console.warn("âš ï¸ ç„¡æ³•è­˜åˆ¥èªéŸ³å…§å®¹");
	}

	onRepeatRequest() {
		// Override in implementation
		console.log("ğŸ”„ è«‹æ±‚é‡è¤‡");
	}

	onClearRequest() {
		// Override in implementation
		console.log("ğŸ—‘ï¸ è«‹æ±‚æ¸…é™¤");
	}

	// Utility methods
	isVoiceInputSupported() {
		return this.isSupported.recognition;
	}

	isVoiceOutputSupported() {
		return this.isSupported.synthesis;
	}

	getAvailableVoices() {
		if (!this.synthesis) return [];
		return this.synthesis.getVoices().map((voice) => ({
			name: voice.name,
			lang: voice.lang,
			isDefault: voice.default,
			isLocal: voice.localService,
		}));
	}

	// Test voice functionality
	async testVoice() {
		console.log("ğŸ§ª æ¸¬è©¦èªéŸ³åŠŸèƒ½...");

		if (this.isSupported.synthesis) {
			await this.speak("èªéŸ³æ¸¬è©¦æˆåŠŸï¼Smart-Chat3 èªéŸ³ç³»çµ±å·²æº–å‚™å°±ç·’ã€‚");
		}

		if (this.isSupported.recognition) {
			console.log("ğŸ¤ è«‹èªªè©±æ¸¬è©¦èªéŸ³è­˜åˆ¥...");
			this.startListening();
		}
	}
}

export default VoiceInterfaceManager;
